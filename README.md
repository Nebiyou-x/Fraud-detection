# ğŸ•µï¸â€â™‚ï¸ Fraud Detection System

## ğŸ“Œ Project Overview

This project focuses on building **robust fraud detection pipelines** using two real-world datasets:

1. **E-commerce transaction data**
2. **Credit card transaction data**

Fraud detection is a highly imbalanced classification problem where fraudulent cases are rare but costly. The project emphasizes:

* Careful data preprocessing
* Meaningful feature engineering
* Correct handling of class imbalance
* Reproducibility and testing
* Model explainability

---

## ğŸ“‚ Datasets

### 1. `Fraud_Data.csv`

E-commerce transactions with user, device, time, and network information.

**Key Columns**

* `user_id` â€“ Unique user identifier
* `signup_time`, `purchase_time` â€“ Timestamps
* `purchase_value` â€“ Transaction amount
* `device_id` â€“ Device identifier
* `source` â€“ Acquisition channel (SEO, Ads, etc.)
* `browser` â€“ Browser type
* `sex`, `age` â€“ User demographics
* `ip_address` â€“ Transaction IP
* `class` â€“ Target (1 = Fraud, 0 = Legitimate)

**Challenge:** Highly imbalanced target variable.

---

### 2. `IpAddress_to_Country.csv`

Maps IP address ranges to countries.

**Columns**

* `lower_bound_ip_address`
* `upper_bound_ip_address`
* `country`

Used to enrich fraud data with **geolocation features**.

---

### 3. `creditcard.csv`

An anonymized credit card transaction dataset.

**Columns**

* `Time` â€“ Seconds since first transaction
* `V1`â€“`V28` â€“ PCA-transformed features
* `Amount` â€“ Transaction amount
* `Class` â€“ Target (1 = Fraud, 0 = Legitimate)

**Challenge:** Extreme class imbalance (~0.2% fraud).

---

## ğŸ—‚ Project Structure

```
fraud-detection/
â”‚
â”œâ”€â”€ data/                    # Ignored by git
â”‚   â”œâ”€â”€ raw/                 # Original datasets
â”‚   â””â”€â”€ processed/           # Cleaned & feature-engineered data
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ eda-fraud-data.ipynb
â”‚   â”œâ”€â”€ eda-creditcard.ipynb
â”‚   â”œâ”€â”€ feature-engineering.ipynb
â”‚   â”œâ”€â”€ modeling.ipynb
â”‚   â”œâ”€â”€ shap-explainability.ipynb
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ src/                     # Reusable source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ preprocessing.py
â”‚
â”œâ”€â”€ tests/                   # Unit tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ test_preprocessing.py
â”‚
â”œâ”€â”€ models/                  # Saved models (ignored by git)
â”‚
â”œâ”€â”€ scripts/                 # Utility scripts
â”‚
â”œâ”€â”€ .github/workflows/
â”‚   â””â”€â”€ unittests.yml        # GitHub Actions CI
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

---

## âš™ï¸ Setup Instructions

### 1. Clone the Repository

```bash
git clone https://github.com/Nebiyou-x/fraud-detection.git
cd fraud-detection
```

### 2. Create a Virtual Environment

```bash
python -m venv venv
source venv/bin/activate  # Mac/Linux
venv\Scripts\activate     # Windows
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸ” Task 1: Data Analysis & Preprocessing

### âœ” Data Cleaning

* Removed duplicates
* Handled missing values (median for numerical, mode/â€œUnknownâ€ for categorical)
* Converted timestamps to `datetime`
* Ensured correct data types

---

### âœ” Exploratory Data Analysis (EDA)

* Univariate and bivariate analysis
* Fraud vs non-fraud comparisons
* Temporal fraud patterns
* Class distribution visualization

ğŸ““ Implemented in:

* `eda-fraud-data.ipynb`
* `eda-creditcard.ipynb`

---

### âœ” Geolocation Integration

* Converted IP addresses to integers
* Used **range-based merge** to map IPs to countries
* Analyzed fraud rates by country

ğŸ“Œ This step significantly improves fraud signal strength.

---

### âœ” Feature Engineering (Fraud_Data.csv)

* **Time-based features**

  * `hour_of_day`
  * `day_of_week`
  * `is_weekend`
* **Behavioral features**

  * `time_since_signup`
  * Transaction frequency per user
  * Time since last transaction
* **Geographical features**

  * Country of transaction

---

### âœ” Data Transformation

* **StandardScaler** for numerical features
* **One-Hot Encoding** for categorical features
* Ensured transformations are reproducible

---

## âš–ï¸ Handling Class Imbalance

Fraud detection suffers from **severe class imbalance**.

### Strategy Used

* **Train/Test split first** (to avoid data leakage)
* **SMOTE** applied only to training data
* Test data kept untouched and imbalanced

### Justification

* SMOTE preserves majority class information
* Improves recall for minority (fraud) class
* Suitable for highly imbalanced datasets

ğŸ“Š Class distributions before and after resampling are documented in notebooks.

---

## ğŸ¤– Modeling (Overview)

* Baseline models: Logistic Regression
* Advanced models: Random Forest, XGBoost
* Metrics used:

  * Precision
  * Recall
  * F1-score
  * ROC-AUC

ğŸ““ Implemented in `modeling.ipynb`

---

## ğŸ” Model Explainability

* SHAP used for global and local explanations
* Identifies most influential fraud features
* Improves model transparency and trust

ğŸ““ Implemented in `shap-explainability.ipynb`

---

## ğŸ§ª Testing & CI

* Unit tests written using **pytest**
* Core preprocessing logic tested
* GitHub Actions automatically runs tests on:

  * Push
  * Pull requests

ğŸ“ Config: `.github/workflows/unittests.yml`

---

## ğŸ“¦ Dependencies

Key libraries:

* pandas, numpy
* scikit-learn
* imbalanced-learn
* xgboost
* shap
* matplotlib, seaborn
* pytest

See `requirements.txt` for full list.

---

## ğŸš€ Key Takeaways

* Fraud detection requires **domain-specific feature engineering**
* Class imbalance must be handled carefully to avoid misleading results
* Geolocation and behavioral features significantly improve detection
* Explainability is essential for real-world fraud systems

---


